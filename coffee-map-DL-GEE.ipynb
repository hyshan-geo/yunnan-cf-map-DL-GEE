{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0a898c-66e5-48ba-91de-63c246d110aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1063a0fc-dfa9-41aa-9a2f-b5c166753c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "\n",
    "import shapely as shp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path as P\n",
    "\n",
    "\n",
    "import ee\n",
    "import geemap\n",
    "# geemap.set_proxy(port=7890)\n",
    "# ee.Authenticate()\n",
    "ee.Initialize(project='ee-shy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d1b0df-1130-4e31-a27f-dfbdaa3ada92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import ast\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7996f544-18b9-4d79-bc6b-d1244dee298c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c73a33c-847e-4893-9ee3-0f923e01bd48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0a69919-41fa-4475-97f7-d71e3a58c6e0",
   "metadata": {},
   "source": [
    "# coffee distibution prediction with geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df6b456-a3b8-444e-b738-a993bfe41f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# model parameters\n",
    "pars_feas = [\n",
    "    [[10,5,50,20], [10,16,8,4]], \n",
    "    [[2,1,2,2], [2,4,4,2]]\n",
    "]\n",
    "# [10,5,50,20] -> [10 bands from Sentinel-2, 5 time periods, 50 inputs features, 20 outputs]\n",
    "# [10,16,8,4] -> full connected network structure for Sentinel bands of each time period \n",
    "# [2,1,2,2] -> [2 topology features, 1, 2 inputs features, 2 outputs]\n",
    "# [2,4,4,2] -> full connected network structure for topology \n",
    "\n",
    "par_merge = [[22,0], [22,32,16,8,1]]\n",
    "# [22,0] -> 22 inputs from the outputs of formal feature preprocessing network\n",
    "# [22,32,16,8,1] -> network structure of feature combination\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    # define model parameters\n",
    "    def __init__(self, pars_feas=None, par_merge=None):  \n",
    "        super(DNN, self).__init__()\n",
    "\n",
    "        self.pars_feas = pars_feas\n",
    "        self.par_merge = par_merge\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # mdl list of all features are combined into one, and each feature is connected by a full connected layer to form an mdl list\n",
    "        list_mdl = []\n",
    "        # pars_fea [10,5,50,20], par_mdl [10,16,8,4]\n",
    "        for pars_fea,par_mdl in pars_feas:\n",
    "            list_mdl_fea = []  # used to store lyr of multiple layer\n",
    "            for t_idx in range(pars_fea[1]):\n",
    "                list_lyr = []\n",
    "                for i in range(len(par_mdl)-1):\n",
    "                    list_lyr.extend([nn.Linear(par_mdl[i],par_mdl[i+1]), self.relu])\n",
    "                list_mdl_fea.append(nn.Sequential(*list_lyr))\n",
    "            list_mdl.append(nn.ModuleList(list_mdl_fea))\n",
    "        self.fcs_fea = nn.ModuleList(list_mdl)\n",
    "\n",
    "        par_lyrs = par_merge[1]\n",
    "        list_lyr = []\n",
    "        for i in range(len(par_lyrs)-2):\n",
    "            list_lyr.extend([nn.Linear(par_lyrs[i],par_lyrs[i+1]), self.relu])\n",
    "        list_lyr.append(nn.Linear(par_lyrs[-2],par_lyrs[-1]))\n",
    "        self.fcs_end = nn.Sequential(*list_lyr)\n",
    "\n",
    "\n",
    "    # forward propagation process\n",
    "    def forward(self, x):\n",
    "        offset = 0\n",
    "        xs = []\n",
    "\n",
    "        # cycle a few times for certain types of features e.g. S2 and topology\n",
    "        for i in range(len(self.pars_feas)):\n",
    "            fea_pars = self.pars_feas[i][0]\n",
    "            # cycle each time period\n",
    "            for t_idx in range(fea_pars[1]):\n",
    "                \n",
    "                x_t = x[:, offset+t_idx*fea_pars[0]: offset+(t_idx+1)*fea_pars[0]]\n",
    "                # print(t_idx, 'x_t', x_t.shape)\n",
    "                xs.append(self.fcs_fea[i][t_idx](x_t))\n",
    "            offset += fea_pars[2]\n",
    "\n",
    "        # for x in xs:\n",
    "        #     print(x.shape)\n",
    "        if self.par_merge[0][1]:\n",
    "            x = torch.cat(xs+[x[:,offset:]], dim=1)\n",
    "        else:\n",
    "            x = torch.cat(xs, dim=1)  \n",
    "        # print(x.shape, self.fcs_end)\n",
    "        x = self.fcs_end(x)\n",
    "\n",
    "        # if it is binary classification, use sigmoid function to convert to binary result\n",
    "        if self.par_merge[-1][-1] == 1:\n",
    "            x = nn.Sigmoid()(x)\n",
    "            x = x.squeeze(-1)\n",
    "            \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0a9afb-7732-4080-9be9-0b602387bb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_mdl_save = 'mdl_pars.pth'\n",
    "\n",
    "# torch.save(mdl, path_mdl_save)\n",
    "\n",
    "mdl = torch.load(path_mdl_save)\n",
    "\n",
    "\n",
    "pars = {}\n",
    "pars_ee = {}\n",
    "for par_name, par_val in mdl.named_parameters():\n",
    "    pars[par_name] = par_val.detach().cpu().numpy().tolist()\n",
    "    pars_ee[par_name] = ee.Image(ee.Array(pars[par_name]))\n",
    "    if 'bias' in par_name:\n",
    "        pars_ee[par_name] = pars_ee[par_name].toArray(1)\n",
    "    # print(par_name, par_val.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a97a8be-3b32-4dc2-8492-1ca64a8c0fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34aeeea5-8f16-48be-852f-d07522db4d4d",
   "metadata": {},
   "source": [
    "## image preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd574b9-8426-49ab-9c4c-d6c3472925cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "bands_s2 = ['blue', 'green', 'red', 're1','re2', 're3', 'nir','re4','swir1', 'swir2']\n",
    "def imgs_s2(roi, date_start, date_end, cloud_p=40):\n",
    "    return indexJoin(\n",
    "        ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(roi)\n",
    "        .filterDate(date_start, date_end).map(maskS2clouds), \n",
    "        ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY'),  'cloud_probability'\n",
    "    ).map(lambda image: image.updateMask(image.select('probability').lte(cloud_p))).select(bands_s2)\n",
    "\n",
    "# maska clouds and rename band\n",
    "def maskS2clouds(image):\n",
    "    qa = image.select('QA60') \n",
    "    mask = qa.bitwiseAnd(1 << 10).eq(0).And(qa.bitwiseAnd(1 << 11).eq(0)).Or(image.select('B2').lte(2000))\n",
    "    return (image.updateMask(mask).select([\n",
    "        'B2','B3','B4','B5','B6', 'B7', 'B8', 'B8A', 'B11','B12'\n",
    "    ], bands_s2).divide(10000)\n",
    "    .copyProperties(image, [\"system:time_start\"]).copyProperties(image))\n",
    "\n",
    "# Merge the S2 cloud probability dataset with the S2 imagery dataset and use the probability file to create a cloud mask on the S2 image\n",
    "def indexJoin(collectionA, collectionB, propertyName):\n",
    "    joined = ee.ImageCollection(ee.Join.saveFirst(propertyName).apply(**{\n",
    "        'primary': collectionA, 'secondary': collectionB,\n",
    "        'condition': ee.Filter.equals(**{'leftField': 'system:index', 'rightField': 'system:index'})\n",
    "    }))\n",
    "    return joined.map(lambda image: image.addBands(ee.Image(image.get(propertyName))))\n",
    "\n",
    "def cal_S_vi(img):\n",
    "  blue = img.select('blue')\n",
    "  green = img.select('green')\n",
    "  red = img.select('red')\n",
    "  re1 = img.select('re1')\n",
    "  re2 = img.select('re2')\n",
    "  re3 = img.select('re3')\n",
    "  re4 = img.select('re4')\n",
    "  nir = img.select('nir')\n",
    "  swir1 = img.select('swir1')\n",
    "  swir2 = img.select('swir2') \n",
    "  \n",
    "  ndti = ee.Image().expression('ndti = (swir1 - swir2) / (swir1 + swir2)', {\"swir1\": swir1, \"swir2\": swir2}) \n",
    "  evi = ee.Image().expression('evi = 2.5 * (nir-red) / ((nir+6*red-7.5*blue) + 1)', {\"nir\": nir, \"red\": red, \"blue\": blue}) \n",
    "  evi2 = ee.Image().expression('evi2 = 2.4 * (nir - red) / (nir + red + 1)', {\"nir\": nir, \"red\": red}) \n",
    "  \n",
    "  ndvi = ee.Image().expression('ndvi = (nir-red) / (nir+red)', {\"nir\": nir, \"red\": red}) \n",
    "  ndvi2 = ee.Image().expression('ndvi2 = (re4-red) / (re4+red)', {\"re4\": re4, \"red\": red}) \n",
    "  kndvi = ndvi.multiply(ndvi).tanh().rename(['kndvi']) \n",
    "  \n",
    "  ndmi = ee.Image().expression('ndmi = (nir - swir1) / (nir + swir1)', {\"nir\": nir, \"swir1\": swir1}) \n",
    "  ndre1 = ee.Image().expression('ndre1 = (re2 - re1) / (re2 + re1)', {\"re1\": re1, \"re2\": re2}) \n",
    "  resi = ee.Image().expression('resi = (re3 + re2 - re1) / (re3 + re2 + re1)', {\"re1\": re1, \"re2\": re2, \"re3\": re3}) \n",
    "  \n",
    "  mtci = ee.Image().expression('mtci = (nir - re1) / (re1-red)', {\"nir\": nir, \"re1\": re1, \"red\": red}) \n",
    "  gcvi = ee.Image().expression('gcvi = (nir / green) - 1', {\"nir\": nir, \"green\": green}) \n",
    "  savi = ee.Image().expression('savi = (nir - red) / (nir + red + 0.428)', {\"nir\": nir, \"red\": red})   # L=0.428 for S2\n",
    "  ndwi = ee.Image().expression('ndwi = (nir - swir1) / (nir + swir1)', {\"swir1\": swir1, \"nir\": nir}) \n",
    "  ndwi2 = ee.Image().expression('ndwi2 = (nir - swir2) / (nir + swir2)', {\"nir\": nir, \"swir2\": swir2}) \n",
    "  # mndwi = ee.Image().expression('mndwi = (green - swir1) / (green + swir1)', {\"green\": green, \"swir1\": swir1}) \n",
    "  \n",
    "  tvi = ee.Image().expression('tvi = 60 * (nir - green) - 100 * (red - green)', {\"nir\": nir, \"red\": red, \"green\": green}) \n",
    "  cvi = ee.Image().expression('cvi = nir * red / (green * green)', {\"nir\": nir, \"red\": red, \"green\": green}) \n",
    "  mcari = ee.Image().expression(\n",
    "    'mcari = ((re1-red) - 0.2*(re1-green)) * (re1/red) / 1.16 / (nir - red) * (nir + red + 0.16)', \n",
    "    {\"nir\": nir, \"red\": red, \"re1\": re1, \"green\": green}\n",
    "  ) \n",
    "  \n",
    "  datt = ee.Image().expression('datt = nir / green / re1', {\"nir\": nir, \"re1\": re1, \"green\": green}) \n",
    "  cire = ee.Image().expression('cire = red - nir/red - re1 - 1', {\"nir\": nir, \"red\": red, \"re1\": re1}) \n",
    "  dbsi = ee.Image().expression('dbsi = (swir1-green)/(swir1+green) - (nir-red)/(nir+red)', \n",
    "    {\"nir\": nir, \"red\": red, \"swir1\": swir1, \"green\": green}\n",
    "  ) \n",
    "  mnbr = ee.Image().expression('mnbr = (nir - swir1 - swir2) / (nir + swir1 + swir2)', {\"nir\": nir, \"swir1\": swir1, \"swir2\": swir2}) \n",
    "  n = ee.Image().expression('n = (2 * (nir*nir - red*red) + 1.5*nir + 0.4*red) / (nir + red + 0.5)', {\"nir\": nir, \"red\": red}) \n",
    "  gemi = ee.Image().expression('gemi = n * (1 - 0.25 * n) - (red-0.125) / (1-red)', {\"red\": red, 'n': n}) \n",
    "  \n",
    "  sti = ee.Image().expression('sti = swir1 / swir2', {\"swir2\": swir2, \"swir1\": swir1}) \n",
    "  rvmi = ee.Image().expression('rvmi = (ndvi - ndwi) / (ndvi + ndwi)', {\"ndvi\": ndvi, \"ndwi\": ndwi}) \n",
    "  # ndti = ee.Image().expression('', {\"nir\": nir, \"red\": red}) \n",
    "  # ndti = ee.Image().expression('', {\"nir\": nir, \"red\": red}) \n",
    "  \n",
    "  return img.addBands([\n",
    "    ndti, evi, evi2, ndvi, ndvi2, kndvi, ndmi, ndre1, resi, mtci, gcvi, savi, ndwi, ndwi2,   # mndwi, \n",
    "    sti, rvmi, tvi, cvi, mcari, datt, cire, mnbr, dbsi, n, gemi  # \n",
    "  ]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefa07dc-51a8-4e2a-beb3-cc62218f228b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a128f23a-4e29-4fdd-8cca-f82fbd6ad3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "band_s2 = 'blue,green,red,re1,re2,re3,nir,re4,swir1,swir2'.split(',')\n",
    "col_s2 = bands_s2 + [f'{b}_{i}' for i in range(1,5) for b in bands_s2]\n",
    "\n",
    "col_s2_band = band_s2 + [f'{b}_{i}' for i in range(1, 5) for b in band_s2]\n",
    "col_s2_band = ['s2_'+c for c in col_s2_band]\n",
    "\n",
    "col_topo = ['elevation', 'slope']  # , 'aspect'\n",
    "\n",
    "cols = col_s2_band + col_topo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192c251-9043-4b54-b7e1-5ac3502aa203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9059f5ee-94ef-48c6-938f-2a5657b67fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# img for pred\n",
    "\n",
    "# mdl pars\n",
    "snic_size = 8\n",
    "\n",
    "# data pars\n",
    "\n",
    "yr_pred = 2022\n",
    "study_area = 'sp_buf_3km'\n",
    "scale = 10\n",
    "city = 'cf_5city'   \n",
    "\n",
    "roi_pred = ee.FeatureCollection(\"projects/ee-shy/assets/coffee/citys/\"+city)\n",
    "ct_5city = ee.FeatureCollection(\"projects/ee-shy/assets/coffee/cts/ct_5city\") \n",
    "  \n",
    "def str_pre(img, pre):\n",
    "  return img.rename(img.bandNames().map( \n",
    "    lambda i: ee.String(pre).cat(ee.String(i))\n",
    "  )) \n",
    "\n",
    "# flex vars, different time period composite\n",
    "\n",
    "# periods of all satellite \n",
    "date_pred_start = ee.Date.fromYMD(yr_pred,4,1)\n",
    "date_pred_end = ee.Date.fromYMD(yr_pred+1,4,1) \n",
    "t_period_pred = ee.List([  # 1 8 9 11\n",
    "  date_pred_start, date_pred_start.advance(7,'month'), date_pred_start.advance(8,'month'), \n",
    "  date_pred_start.advance(10,'month'), date_pred_start.advance(11,'month'), date_pred_end\n",
    "]) \n",
    "\n",
    "img_pred = ee.Image([0])  \n",
    "\n",
    "# cal of s2 features\n",
    "imgs = imgs_s2(roi_pred, date_pred_start, date_pred_end) \n",
    "\n",
    "for i in range(t_period_pred.length().getInfo()-1):\n",
    "\n",
    "  img = imgs.filterDate(t_period_pred.get(i), t_period_pred.get(i+1)).median().clip(roi_pred) \n",
    "  # Map.addLayer(img, vis_rgb, 'S_'+i, false) \n",
    "  img_s2_feas = str_pre(cal_S_vi(img), 's2_')   # cal_S_vi(img) img\n",
    "  img_pred = img_pred.addBands(img_s2_feas)   # s2 features  VIs\n",
    "  # img_pred = img_pred.addBands(img)   # original s2 bands\n",
    "\n",
    "# Map.addLayer(img, vis_rgb, 'img pred', false) \n",
    "\n",
    "\n",
    "snic = ee.Algorithms.Image.Segmentation.SNIC(\n",
    "  image=img_pred.select(col_s2_band), size=snic_size, compactness=.1, connectivity=8, neighborhoodSize=64,\n",
    ")\n",
    "# print('snic', snic)\n",
    "clusters = snic.select('clusters')\n",
    "# Map.addLayer(clusters.randomVisualizer(), {}, 'clusters pred')\n",
    "\n",
    "img_pred = snic.rename([n.replace('_mean', '') for n in snic.bandNames().getInfo()])  # .select(sel_feas)\n",
    "\n",
    "\n",
    "\n",
    "dem = ee.Image('USGS/SRTMGL1_003').clip(roi_pred).float() \n",
    "img_pred = img_pred.addBands([dem, ee.Terrain.slope(dem), ee.Terrain.aspect(dem)])  # .select(sel_feas)  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2bdee7-3a4c-4b53-8d44-539cae481363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d499dd9-e90b-4d12-bfbd-1d2b0f0f5890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9441c-4be5-46ee-834f-1e37f6c9e699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0707a4bd-bb7f-422e-bc20-524125924bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e3db713-0f49-4b54-a55d-dafd5e1a4df4",
   "metadata": {},
   "source": [
    "## predict coffee distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374fd448-62da-4ff7-aca8-d13a198e9ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# col_topo = ['elevation', 'slope']  # , 'aspect'\n",
    "\n",
    "# prediction  \n",
    "\n",
    "img_todo = img_pred\n",
    "roi_todo = roi_pred\n",
    "\n",
    "# fcs_fea.0/1.0~4.0/2/4/6.weight\n",
    "# fcs_fea.0.0.0.bias\n",
    "\n",
    "def cat_img(imgs):\n",
    "    img = imgs[0]\n",
    "    for i in range(1, len(imgs)):\n",
    "        img = img.arrayCat(imgs[i], axis=0)\n",
    "    return img\n",
    "\n",
    "imgs_fea = []\n",
    "offset = 0\n",
    "\n",
    "imgs_sub = []\n",
    "for idx_fea in range(len(pars_feas)):\n",
    "    pars_fea, par_mdl = pars_feas[idx_fea]\n",
    "    n_bands, n_ts, offset_fea, n_fea_out = pars_fea\n",
    "\n",
    "    for t_idx in range(n_ts):\n",
    "        # print(cols[offset+t_idx*n_bands: offset+(t_idx+1)*n_bands])\n",
    "        \n",
    "        img_t = img_todo.select(cols[offset+t_idx*n_bands: offset+(t_idx+1)*n_bands]).toArray().toArray(1)\n",
    "        # Map.addLayer(img_t.arrayLengths().arrayFlatten([['a','b']]), {}, f'{k}, {t_idx}')\n",
    "        # if idx_fea:\n",
    "        #     print('idx_fea', idx_fea, 't', t_idx, 'dim', img_t.arrayDimensions().getInfo())\n",
    "        for lyr_idx in range(len(par_mdl)-1):\n",
    "            # print(f'k: {k}, t: {t_idx}, lyr: {lyr_idx}', pars[f'fcs_{k}.{t_idx}.{lyr_idx*2}.weight'].shape)\n",
    "            w = pars_ee[f'fcs_fea.{idx_fea}.{t_idx}.{lyr_idx*2}.weight']\n",
    "            b = pars_ee[f'fcs_fea.{idx_fea}.{t_idx}.{lyr_idx*2}.bias']\n",
    "            img_t = w.matrixMultiply(img_t).add(b)\n",
    "            img_t = img_t.gt(0).multiply(img_t)\n",
    "        imgs_sub.append(img_t)\n",
    "    \n",
    "    offset += offset_fea\n",
    "    \n",
    "\n",
    "if par_merge[0][1]:\n",
    "    imgs_sub.append(img_todo.select(cols[offset: ]).toArray().toArray(1))\n",
    "\n",
    "img = cat_img(imgs_sub)\n",
    "\n",
    "# fcs_end.0/2/4/6.weight \n",
    "# fcs_end.0.bias\n",
    "\n",
    "n_lyr_end = len(par_merge[1])-1\n",
    "for fc_idx in range(n_lyr_end):\n",
    "    img = pars_ee[f'fcs_end.{fc_idx*2}.weight'].matrixMultiply(img).add(pars_ee[f'fcs_end.{fc_idx*2}.bias'])\n",
    "\n",
    "    if fc_idx == n_lyr_end-1:\n",
    "        if par_merge[-1][-1] == 1:\n",
    "            # binary classification\n",
    "            img = ee.Image(1).divide(img.arrayGet([0,0]).clip(roi_todo).multiply(-1).exp().add(ee.Image(1))).clip(roi_todo)\n",
    "        else:\n",
    "            # multi classification\n",
    "            exp_arr = img.exp()\n",
    "            sum_exp = exp_arr.arrayReduce(ee.Reducer.sum(), [0]).arrayRepeat(0, par_merge[-1][-1])\n",
    "            img = exp_arr.divide(sum_exp).arrayProject([0]).arrayArgmax().arrayFlatten([['class']])\n",
    "        # print('fc_idx', fc_idx, 'dim', img.arrayDimensions().getInfo())\n",
    "    else:\n",
    "        img = img.gt(0).multiply(img)\n",
    "\n",
    "if par_merge[-1][-1] == 1:\n",
    "    img_res = img.gt(0.5).selfMask()\n",
    "else:\n",
    "    img_res = img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71cb82b-1e9d-4743-98a4-d70dc0f21bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd677426-dd19-4bb7-9c1f-05e4c1ad234f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b7b050921f4f0a9bf5737a3570b098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[0, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=SearchDataGUI(childr…"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize result\n",
    "\n",
    "palette = ['FF0000', 'e8beff', 'aaff00', '38a800', 'ffffbe', 'e1e1e1', '73b2ff']\n",
    "names = ['coffee', 'cropland', 'sparse_veg', 'forest', 'bare', 'build', 'water']\n",
    "\n",
    "Map = geemap.Map()\n",
    "Map.addLayer(img_res, {'min': 1, 'max': 7, 'palette': palette}, 'res')  #  pixel\n",
    "Map.centerObject(roi_pred)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc0892-b518-42a3-8dfa-13aa36df1893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa78dd6-a619-4f4b-b452-3576e9ebc862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expor result\n",
    "fn = '2022_yunnan_coffee_10m'\n",
    "print(fn)  \n",
    "task = ee.batch.Export.image.toDrive(\n",
    "    image=img_res.int8(), region=roi_pred.geometry(), description=fn,\n",
    "    folder='GEE_data', maxPixels=1e11, scale=30, crs='EPSG:4326'\n",
    ")\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e18043-8579-4bac-be8f-18935dac24be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "324b254c-a688-4435-8eb4-bc784a17c489",
   "metadata": {},
   "source": [
    "# DL model training with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caedf430-bcf4-435e-9005-e274665a4817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "842859a7",
   "metadata": {},
   "source": [
    "## training data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd5aa76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e521a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f396774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edb8b44c",
   "metadata": {},
   "source": [
    "## model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6b7a0c-1ea3-483d-9154-68a167133ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# model parameters\n",
    "pars_feas = [\n",
    "    [[10,5,50,20], [10,16,8,4]], \n",
    "    [[2,1,2,2], [2,4,4,2]]\n",
    "]\n",
    "# [10,5,50,20] -> [10 bands from Sentinel-2, 5 time periods, 50 inputs features, 20 outputs]\n",
    "# [10,16,8,4] -> full connected network structure for Sentinel bands of each time period \n",
    "# [2,1,2,2] -> [2 topology features, 1, 2 inputs features, 2 outputs]\n",
    "# [2,4,4,2] -> full connected network structure for topology \n",
    "\n",
    "par_merge = [[22,0], [22,32,16,8,1]]\n",
    "# [22,0] -> 22 inputs from the outputs of formal feature preprocessing network\n",
    "# [22,32,16,8,1] -> network structure of feature combination\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    # define model parameters\n",
    "    def __init__(self, pars_feas=None, par_merge=None):  \n",
    "        super(DNN, self).__init__()\n",
    "\n",
    "        self.pars_feas = pars_feas\n",
    "        self.par_merge = par_merge\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # mdl list of all features are combined into one, and each feature is connected by a full connected layer to form an mdl list\n",
    "        list_mdl = []\n",
    "        # pars_fea [10,5,50,20], par_mdl [10,16,8,4]\n",
    "        for pars_fea,par_mdl in pars_feas:\n",
    "            list_mdl_fea = []  # used to store lyr of multiple layer\n",
    "            for t_idx in range(pars_fea[1]):\n",
    "                list_lyr = []\n",
    "                for i in range(len(par_mdl)-1):\n",
    "                    list_lyr.extend([nn.Linear(par_mdl[i],par_mdl[i+1]), self.relu])\n",
    "                list_mdl_fea.append(nn.Sequential(*list_lyr))\n",
    "            list_mdl.append(nn.ModuleList(list_mdl_fea))\n",
    "        self.fcs_fea = nn.ModuleList(list_mdl)\n",
    "\n",
    "        par_lyrs = par_merge[1]\n",
    "        list_lyr = []\n",
    "        for i in range(len(par_lyrs)-2):\n",
    "            list_lyr.extend([nn.Linear(par_lyrs[i],par_lyrs[i+1]), self.relu])\n",
    "        list_lyr.append(nn.Linear(par_lyrs[-2],par_lyrs[-1]))\n",
    "        self.fcs_end = nn.Sequential(*list_lyr)\n",
    "\n",
    "\n",
    "    # forward propagation process\n",
    "    def forward(self, x):\n",
    "        offset = 0\n",
    "        xs = []\n",
    "\n",
    "        # cycle a few times for certain types of features e.g. S2 and topology\n",
    "        for i in range(len(self.pars_feas)):\n",
    "            fea_pars = self.pars_feas[i][0]\n",
    "            # cycle each time period\n",
    "            for t_idx in range(fea_pars[1]):\n",
    "                \n",
    "                x_t = x[:, offset+t_idx*fea_pars[0]: offset+(t_idx+1)*fea_pars[0]]\n",
    "                # print(t_idx, 'x_t', x_t.shape)\n",
    "                xs.append(self.fcs_fea[i][t_idx](x_t))\n",
    "            offset += fea_pars[2]\n",
    "\n",
    "        # for x in xs:\n",
    "        #     print(x.shape)\n",
    "        if self.par_merge[0][1]:\n",
    "            x = torch.cat(xs+[x[:,offset:]], dim=1)\n",
    "        else:\n",
    "            x = torch.cat(xs, dim=1)  \n",
    "        # print(x.shape, self.fcs_end)\n",
    "        x = self.fcs_end(x)\n",
    "\n",
    "        # if it is binary classification, use sigmoid function to convert to binary result\n",
    "        if self.par_merge[-1][-1] == 1:\n",
    "            x = nn.Sigmoid()(x)\n",
    "            x = x.squeeze(-1)\n",
    "            \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b424102-6b2b-448f-9f09-dc200fe31f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if par_merge[-1][-1] == 1:\n",
    "    criterion = nn.BCELoss()  # binary classification\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "mdl = DNN(pars_feas=pars_feas, par_merge=par_merge).to(device)\n",
    "optimizer = optim.Adam(mdl.parameters(), lr=0.001)  # , weight_decay=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ade7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7298a1ca",
   "metadata": {},
   "source": [
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bece36-1aa1-4a3b-a4ba-4182c6fdb138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "num_epochs = 200\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "assess = []\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    mdl.train()\n",
    "\n",
    "    train_loss_list, train_metric_list = [],[]\n",
    "\n",
    "    for inputs, labels in trainLoader:\n",
    "        # print('ipt_size', inputs.size())\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = mdl(inputs)\n",
    "        if par_merge[-1][-1] == 1:\n",
    "            labels = labels.squeeze(-1)\n",
    "        loss_i = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_i.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_list.append(loss_i.detach().cpu().numpy())\n",
    "\n",
    "    loss = np.mean(train_loss_list)\n",
    "\n",
    "    # 验证精度\n",
    "    mdl.eval()\n",
    "\n",
    "    outputs_list = []\n",
    "    labels_list = []\n",
    "    with torch.no_grad():\n",
    "        for ipts, lbls in valLoader:\n",
    "            inputs, labels = ipts.to(device), lbls.numpy()\n",
    "            outputs = mdl(inputs)\n",
    "\n",
    "            if par_merge[-1][-1] == 1:\n",
    "                outputs_list.append(outputs.detach().cpu().numpy())\n",
    "            else:\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                predicted = predicted.detach().cpu().numpy()\n",
    "                outputs_list.append(predicted)\n",
    "            \n",
    "            labels_list.append(labels)\n",
    "\n",
    "    if par_merge[-1][-1] == 1:\n",
    "        y_pred = np.concatenate(outputs_list) > 0.5\n",
    "    else:\n",
    "        y_pred = np.concatenate(outputs_list)\n",
    "    y_test = np.concatenate(labels_list)\n",
    "\n",
    "    s_report = sk.metrics.classification_report(y_test, y_pred)\n",
    "    report_res = s_report.split()\n",
    "    kp = sk.metrics.cohen_kappa_score(y_test, y_pred)\n",
    "    assess.append([epoch, loss]+report_res[5:8]+[report_res[report_res.index('accuracy')+1], kp])\n",
    "\n",
    "    if epoch%20 == 0:\n",
    "        # 在每个epoch结束后，计算并输出训练集的损失\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Train loss: {loss.item():.4f}, acc:{assess[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037c9b74-0e0c-49ca-8ea5-0cca05d26e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(assess).to_excel(f'result/mdl/DL_2022_{study_area_fn}_2yr.xlsx')  # data_path / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20290c02-c382-4370-809b-44a46cc9b259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a93a07-e976-4d40-a110-cf8b16defec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mdl_save = 'mdl_pars.pth'\n",
    "\n",
    "torch.save(mdl, path_mdl_save)\n",
    "mdl = torch.load(path_mdl_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8010a919-016e-432c-8c11-caa54ba91d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (relu): ReLU()\n",
       "  (fcs_fea): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=10, out_features=16, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=16, out_features=8, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=8, out_features=4, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=10, out_features=16, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=16, out_features=8, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=8, out_features=4, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Linear(in_features=10, out_features=16, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=16, out_features=8, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=8, out_features=4, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Linear(in_features=10, out_features=16, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=16, out_features=8, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=8, out_features=4, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Linear(in_features=10, out_features=16, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=16, out_features=8, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=8, out_features=4, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=4, out_features=4, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=4, out_features=2, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fcs_end): Sequential(\n",
       "    (0): Linear(in_features=22, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=8, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb96230-1c57-4bb7-b044-252fa7c3c693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
