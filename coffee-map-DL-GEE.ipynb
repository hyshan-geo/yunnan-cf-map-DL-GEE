{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0a898c-66e5-48ba-91de-63c246d110aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1063a0fc-dfa9-41aa-9a2f-b5c166753c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "\n",
    "import shapely as shp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path as P\n",
    "\n",
    "\n",
    "# import ee\n",
    "# import geemap\n",
    "# geemap.set_proxy(port=7890)\n",
    "# ee.Authenticate()\n",
    "# ee.Initialize(project='ee-shy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90d1b0df-1130-4e31-a27f-dfbdaa3ada92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ast\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7996f544-18b9-4d79-bc6b-d1244dee298c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c73a33c-847e-4893-9ee3-0f923e01bd48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0a69919-41fa-4475-97f7-d71e3a58c6e0",
   "metadata": {},
   "source": [
    "# coffee distibution prediction with geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df6b456-a3b8-444e-b738-a993bfe41f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# model parameters\n",
    "pars_feas = [\n",
    "    [[10,5,50,20], [10,12,12,4]]\n",
    "]\n",
    "# [10,5,50,20] -> [10 bands from Sentinel-2, 5 time periods, 50 inputs features, 20 outputs]\n",
    "# [10,12,12,4] -> full connected network structure for Sentinel bands of each time period \n",
    "\n",
    "\n",
    "par_merge = [[22,0], [22,16,8,4,1]]\n",
    "# [22,0] -> 22 inputs from the outputs of formal feature preprocessing network\n",
    "# [22,16,8,4,1] -> network structure of feature combination\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    # define model parameters\n",
    "    def __init__(self, pars_feas=None, par_merge=None):  \n",
    "        super(DNN, self).__init__()\n",
    "\n",
    "        self.pars_feas = pars_feas\n",
    "        self.par_merge = par_merge\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # mdl list of all features are combined into one, and each feature is connected by a full connected layer to form an mdl list\n",
    "        list_mdl = []\n",
    "        # pars_fea [10,5,50,20], par_mdl [10,16,8,4]\n",
    "        for pars_fea,par_mdl in pars_feas:\n",
    "            list_mdl_fea = []  # used to store lyr of multiple layer\n",
    "            for t_idx in range(pars_fea[1]):\n",
    "                list_lyr = []\n",
    "                for i in range(len(par_mdl)-1):\n",
    "                    list_lyr.extend([nn.Linear(par_mdl[i],par_mdl[i+1]), self.relu])\n",
    "                list_mdl_fea.append(nn.Sequential(*list_lyr))\n",
    "            list_mdl.append(nn.ModuleList(list_mdl_fea))\n",
    "        self.fcs_fea = nn.ModuleList(list_mdl)\n",
    "\n",
    "        par_lyrs = par_merge[1]\n",
    "        list_lyr = []\n",
    "        for i in range(len(par_lyrs)-2):\n",
    "            list_lyr.extend([nn.Linear(par_lyrs[i],par_lyrs[i+1]), self.relu])\n",
    "        list_lyr.append(nn.Linear(par_lyrs[-2],par_lyrs[-1]))\n",
    "        self.fcs_end = nn.Sequential(*list_lyr)\n",
    "\n",
    "\n",
    "    # forward propagation process\n",
    "    def forward(self, x):\n",
    "        offset = 0\n",
    "        xs = []\n",
    "\n",
    "        # cycle a few times for certain types of features e.g. S2 and topology\n",
    "        for i in range(len(self.pars_feas)):\n",
    "            fea_pars = self.pars_feas[i][0]\n",
    "            # cycle each time period\n",
    "            for t_idx in range(fea_pars[1]):\n",
    "                \n",
    "                x_t = x[:, offset+t_idx*fea_pars[0]: offset+(t_idx+1)*fea_pars[0]]\n",
    "                # print(t_idx, 'x_t', x_t.shape)\n",
    "                xs.append(self.fcs_fea[i][t_idx](x_t))\n",
    "            offset += fea_pars[2]\n",
    "\n",
    "        # for x in xs:\n",
    "        #     print(x.shape)\n",
    "        if self.par_merge[0][1]:\n",
    "            x = torch.cat(xs+[x[:,offset:]], dim=1)\n",
    "        else:\n",
    "            x = torch.cat(xs, dim=1)  \n",
    "        # print(x.shape, self.fcs_end)\n",
    "        x = self.fcs_end(x)\n",
    "\n",
    "        # if it is binary classification, use sigmoid function to convert to binary result\n",
    "        if self.par_merge[-1][-1] == 1:\n",
    "            x = nn.Sigmoid()(x)\n",
    "            x = x.squeeze(-1)\n",
    "            \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a9afb-7732-4080-9be9-0b602387bb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mdl_save = 'mdl_pars.pth'\n",
    "\n",
    "# torch.save(mdl, path_mdl_save)\n",
    "\n",
    "mdl = torch.load(path_mdl_save)\n",
    "\n",
    "\n",
    "pars = {}\n",
    "pars_ee = {}\n",
    "for par_name, par_val in mdl.named_parameters():\n",
    "    pars[par_name] = par_val.detach().cpu().numpy().tolist()\n",
    "    pars_ee[par_name] = ee.Image(ee.Array(pars[par_name]))\n",
    "    if 'bias' in par_name:\n",
    "        pars_ee[par_name] = pars_ee[par_name].toArray(1)\n",
    "    # print(par_name, par_val.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a97a8be-3b32-4dc2-8492-1ca64a8c0fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34aeeea5-8f16-48be-852f-d07522db4d4d",
   "metadata": {},
   "source": [
    "## image preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd574b9-8426-49ab-9c4c-d6c3472925cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "bands_s2 = ['blue', 'green', 'red', 're1','re2', 're3', 'nir','re4','swir1', 'swir2']\n",
    "def imgs_s2(roi, date_start, date_end, cloud_p=40):\n",
    "    return indexJoin(\n",
    "        ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(roi)\n",
    "        .filterDate(date_start, date_end).map(maskS2clouds), \n",
    "        ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY'),  'cloud_probability'\n",
    "    ).map(lambda image: image.updateMask(image.select('probability').lte(cloud_p))).select(bands_s2)\n",
    "\n",
    "# maska clouds and rename band\n",
    "def maskS2clouds(image):\n",
    "    qa = image.select('QA60') \n",
    "    mask = qa.bitwiseAnd(1 << 10).eq(0).And(qa.bitwiseAnd(1 << 11).eq(0)).Or(image.select('B2').lte(2000))\n",
    "    return (image.updateMask(mask).select([\n",
    "        'B2','B3','B4','B5','B6', 'B7', 'B8', 'B8A', 'B11','B12'\n",
    "    ], bands_s2).divide(10000)\n",
    "    .copyProperties(image, [\"system:time_start\"]).copyProperties(image))\n",
    "\n",
    "# Merge the S2 cloud probability dataset with the S2 imagery dataset and use the probability file to create a cloud mask on the S2 image\n",
    "def indexJoin(collectionA, collectionB, propertyName):\n",
    "    joined = ee.ImageCollection(ee.Join.saveFirst(propertyName).apply(**{\n",
    "        'primary': collectionA, 'secondary': collectionB,\n",
    "        'condition': ee.Filter.equals(**{'leftField': 'system:index', 'rightField': 'system:index'})\n",
    "    }))\n",
    "    return joined.map(lambda image: image.addBands(ee.Image(image.get(propertyName))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefa07dc-51a8-4e2a-beb3-cc62218f228b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a128f23a-4e29-4fdd-8cca-f82fbd6ad3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "band_s2 = 'blue,green,red,re1,re2,re3,nir,re4,swir1,swir2'.split(',')\n",
    "col_s2 = bands_s2 + [f'{b}_{i}' for i in range(1,5) for b in bands_s2]\n",
    "\n",
    "col_s2_band = band_s2 + [f'{b}_{i}' for i in range(1, 5) for b in band_s2]\n",
    "col_s2_band = ['s2_'+c for c in col_s2_band]\n",
    "\n",
    "col_topo = ['elevation', 'slope']  # , 'aspect'\n",
    "\n",
    "cols = col_s2_band + col_topo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192c251-9043-4b54-b7e1-5ac3502aa203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9059f5ee-94ef-48c6-938f-2a5657b67fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# img for pred\n",
    "\n",
    "# mdl pars\n",
    "snic_size = 8\n",
    "\n",
    "# data pars\n",
    "\n",
    "yr_pred = 2022\n",
    "study_area = 'sp_buf_3km'\n",
    "scale = 10\n",
    "city = 'cf_5city'   \n",
    "\n",
    "roi_pred = ee.FeatureCollection(\"projects/ee-shy/assets/coffee/citys/\"+city)\n",
    "ct_5city = ee.FeatureCollection(\"projects/ee-shy/assets/coffee/cts/ct_5city\") \n",
    "  \n",
    "def str_pre(img, pre):\n",
    "  return img.rename(img.bandNames().map( \n",
    "    lambda i: ee.String(pre).cat(ee.String(i))\n",
    "  )) \n",
    "\n",
    "# flex vars, different time period composite\n",
    "\n",
    "# periods of all satellite \n",
    "date_pred_start = ee.Date.fromYMD(yr_pred,4,1)\n",
    "date_pred_end = ee.Date.fromYMD(yr_pred+1,4,1) \n",
    "t_period_pred = ee.List([  # 1 8 9 11\n",
    "  date_pred_start, date_pred_start.advance(7,'month'), date_pred_start.advance(8,'month'), \n",
    "  date_pred_start.advance(10,'month'), date_pred_start.advance(11,'month'), date_pred_end\n",
    "]) \n",
    "\n",
    "img_pred = ee.Image([0])  \n",
    "\n",
    "# cal of s2 features\n",
    "imgs = imgs_s2(roi_pred, date_pred_start, date_pred_end) \n",
    "\n",
    "for i in range(t_period_pred.length().getInfo()-1):\n",
    "\n",
    "  img = imgs.filterDate(t_period_pred.get(i), t_period_pred.get(i+1)).median().clip(roi_pred) \n",
    "  # Map.addLayer(img, vis_rgb, 'S_'+i, false) \n",
    "  img_s2_feas = str_pre(cal_S_vi(img), 's2_')   # cal_S_vi(img) img\n",
    "  img_pred = img_pred.addBands(img_s2_feas)   # s2 features  VIs\n",
    "  # img_pred = img_pred.addBands(img)   # original s2 bands\n",
    "\n",
    "# Map.addLayer(img, vis_rgb, 'img pred', false) \n",
    "\n",
    "\n",
    "snic = ee.Algorithms.Image.Segmentation.SNIC(\n",
    "  image=img_pred.select(col_s2_band), size=snic_size, compactness=.1, connectivity=8, neighborhoodSize=64,\n",
    ")\n",
    "# print('snic', snic)\n",
    "clusters = snic.select('clusters')\n",
    "# Map.addLayer(clusters.randomVisualizer(), {}, 'clusters pred')\n",
    "\n",
    "img_pred = snic.rename([n.replace('_mean', '') for n in snic.bandNames().getInfo()])  # .select(sel_feas)\n",
    "\n",
    "\n",
    "\n",
    "dem = ee.Image('USGS/SRTMGL1_003').clip(roi_pred).float() \n",
    "img_pred = img_pred.addBands([dem, ee.Terrain.slope(dem), ee.Terrain.aspect(dem)])  # .select(sel_feas)  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2bdee7-3a4c-4b53-8d44-539cae481363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d499dd9-e90b-4d12-bfbd-1d2b0f0f5890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9441c-4be5-46ee-834f-1e37f6c9e699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0707a4bd-bb7f-422e-bc20-524125924bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e3db713-0f49-4b54-a55d-dafd5e1a4df4",
   "metadata": {},
   "source": [
    "## predict coffee distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374fd448-62da-4ff7-aca8-d13a198e9ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# col_topo = ['elevation', 'slope']  # , 'aspect'\n",
    "\n",
    "# prediction  \n",
    "\n",
    "img_todo = img_pred\n",
    "roi_todo = roi_pred\n",
    "\n",
    "# fcs_fea.0/1.0~4.0/2/4/6.weight\n",
    "# fcs_fea.0.0.0.bias\n",
    "\n",
    "def cat_img(imgs):\n",
    "    img = imgs[0]\n",
    "    for i in range(1, len(imgs)):\n",
    "        img = img.arrayCat(imgs[i], axis=0)\n",
    "    return img\n",
    "\n",
    "imgs_fea = []\n",
    "offset = 0\n",
    "\n",
    "imgs_sub = []\n",
    "for idx_fea in range(len(pars_feas)):\n",
    "    pars_fea, par_mdl = pars_feas[idx_fea]\n",
    "    n_bands, n_ts, offset_fea, n_fea_out = pars_fea\n",
    "\n",
    "    for t_idx in range(n_ts):\n",
    "        # print(cols[offset+t_idx*n_bands: offset+(t_idx+1)*n_bands])\n",
    "        \n",
    "        img_t = img_todo.select(cols[offset+t_idx*n_bands: offset+(t_idx+1)*n_bands]).toArray().toArray(1)\n",
    "        # Map.addLayer(img_t.arrayLengths().arrayFlatten([['a','b']]), {}, f'{k}, {t_idx}')\n",
    "        # if idx_fea:\n",
    "        #     print('idx_fea', idx_fea, 't', t_idx, 'dim', img_t.arrayDimensions().getInfo())\n",
    "        for lyr_idx in range(len(par_mdl)-1):\n",
    "            # print(f'k: {k}, t: {t_idx}, lyr: {lyr_idx}', pars[f'fcs_{k}.{t_idx}.{lyr_idx*2}.weight'].shape)\n",
    "            w = pars_ee[f'fcs_fea.{idx_fea}.{t_idx}.{lyr_idx*2}.weight']\n",
    "            b = pars_ee[f'fcs_fea.{idx_fea}.{t_idx}.{lyr_idx*2}.bias']\n",
    "            img_t = w.matrixMultiply(img_t).add(b)\n",
    "            img_t = img_t.gt(0).multiply(img_t)\n",
    "        imgs_sub.append(img_t)\n",
    "    \n",
    "    offset += offset_fea\n",
    "    \n",
    "\n",
    "if par_merge[0][1]:\n",
    "    imgs_sub.append(img_todo.select(cols[offset: ]).toArray().toArray(1))\n",
    "\n",
    "img = cat_img(imgs_sub)\n",
    "\n",
    "# fcs_end.0/2/4/6.weight \n",
    "# fcs_end.0.bias\n",
    "\n",
    "n_lyr_end = len(par_merge[1])-1\n",
    "for fc_idx in range(n_lyr_end):\n",
    "    img = pars_ee[f'fcs_end.{fc_idx*2}.weight'].matrixMultiply(img).add(pars_ee[f'fcs_end.{fc_idx*2}.bias'])\n",
    "\n",
    "    if fc_idx == n_lyr_end-1:\n",
    "        if par_merge[-1][-1] == 1:\n",
    "            # binary classification\n",
    "            img = ee.Image(1).divide(img.arrayGet([0,0]).clip(roi_todo).multiply(-1).exp().add(ee.Image(1))).clip(roi_todo)\n",
    "        else:\n",
    "            # multi classification\n",
    "            exp_arr = img.exp()\n",
    "            sum_exp = exp_arr.arrayReduce(ee.Reducer.sum(), [0]).arrayRepeat(0, par_merge[-1][-1])\n",
    "            img = exp_arr.divide(sum_exp).arrayProject([0]).arrayArgmax().arrayFlatten([['class']])\n",
    "        # print('fc_idx', fc_idx, 'dim', img.arrayDimensions().getInfo())\n",
    "    else:\n",
    "        img = img.gt(0).multiply(img)\n",
    "\n",
    "if par_merge[-1][-1] == 1:\n",
    "    img_res = img.gt(0.5).selfMask()\n",
    "else:\n",
    "    img_res = img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71cb82b-1e9d-4743-98a4-d70dc0f21bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd677426-dd19-4bb7-9c1f-05e4c1ad234f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b7b050921f4f0a9bf5737a3570b098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[0, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=SearchDataGUI(childr…"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize result\n",
    "\n",
    "palette = ['FF0000', 'e8beff', 'aaff00', '38a800', 'ffffbe', 'e1e1e1', '73b2ff']\n",
    "names = ['coffee', 'cropland', 'sparse_veg', 'forest', 'bare', 'build', 'water']\n",
    "\n",
    "Map = geemap.Map()\n",
    "Map.addLayer(img_res, {'min': 1, 'max': 7, 'palette': palette}, 'res')  #  pixel\n",
    "Map.centerObject(roi_pred)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc0892-b518-42a3-8dfa-13aa36df1893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa78dd6-a619-4f4b-b452-3576e9ebc862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expor result\n",
    "fn = '2022_yunnan_coffee_10m'\n",
    "print(fn)  \n",
    "task = ee.batch.Export.image.toDrive(\n",
    "    image=img_res.int8(), region=roi_pred.geometry(), description=fn,\n",
    "    folder='GEE_data', maxPixels=1e11, scale=30, crs='EPSG:4326'\n",
    ")\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e18043-8579-4bac-be8f-18935dac24be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "324b254c-a688-4435-8eb4-bc784a17c489",
   "metadata": {},
   "source": [
    "# DL model training with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caedf430-bcf4-435e-9005-e274665a4817",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sklearn as sk\n",
    "# import sklearn.ensemble\n",
    "# import sklearn.model_selection\n",
    "# import sklearn.inspection\n",
    "# import sklearn.datasets\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842859a7",
   "metadata": {},
   "source": [
    "## training data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd5aa76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e521a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s2_blue', 's2_green', 's2_red', 's2_re1', 's2_re2', 's2_re3', 's2_nir', 's2_re4', 's2_swir1', 's2_swir2', 's2_blue_1', 's2_green_1', 's2_red_1', 's2_re1_1', 's2_re2_1', 's2_re3_1', 's2_nir_1', 's2_re4_1', 's2_swir1_1', 's2_swir2_1', 's2_blue_2', 's2_green_2', 's2_red_2', 's2_re1_2', 's2_re2_2', 's2_re3_2', 's2_nir_2', 's2_re4_2', 's2_swir1_2', 's2_swir2_2', 's2_blue_3', 's2_green_3', 's2_red_3', 's2_re1_3', 's2_re2_3', 's2_re3_3', 's2_nir_3', 's2_re4_3', 's2_swir1_3', 's2_swir2_3', 's2_blue_4', 's2_green_4', 's2_red_4', 's2_re1_4', 's2_re2_4', 's2_re3_4', 's2_nir_4', 's2_re4_4', 's2_swir1_4', 's2_swir2_4', 'elevation', 'slope', 'class_2typ', 'geometry']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((85044, 54), (85044, 52), (25955, 54), (25955, 52))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# snic_size = 8\n",
    "yr_train = 2022\n",
    "\n",
    "\n",
    "band_s2 = ['blue', 'green', 'red', 're1', 're2', 're3', 'nir', 're4', 'swir1', 'swir2']\n",
    "\n",
    "df_train = gdf_train = gpd.read_file('data_train.shp')\n",
    "df_test = gdf_test = gpd.read_file('data_test.shp')\n",
    "\n",
    "\n",
    "# topographic feature\n",
    "col_topo = ['elevation', 'slope']  # , 'aspect'\n",
    "\n",
    "# features of Sentinel-2 frequency bands at different time periods\n",
    "col_s2_band = band_s2 + [f'{b}_{i}' for i in range(1, 5) for b in band_s2]\n",
    "col_s2_band = ['s2_'+c for c in col_s2_band]\n",
    "cols = col_s2_band + col_topo\n",
    "\n",
    "# column of catogory \n",
    "col_type = 'class_2typ' \n",
    "\n",
    "print(gdf_train.columns.to_list())\n",
    "\n",
    "# remove null values\n",
    "x_train, y_train = df_train.loc[:, cols], df_train[col_type]\n",
    "idx = ~(x_train.isnull() | np.isinf(x_train)).any(axis=1)\n",
    "x_train, y_train = x_train.loc[idx, ], y_train.loc[idx, ]\n",
    "\n",
    "x_test, y_test = df_test.loc[:, cols], df_test[col_type]\n",
    "idx = ~(x_test.isnull() | np.isinf(x_test)).any(axis=1)\n",
    "x_test, y_test = x_test.loc[idx, ], y_test.loc[idx, ]\n",
    "\n",
    "# Standardizing before random forest can improve data processing efficiency\n",
    "# avg, std = x_train.mean(), x_train.std()\n",
    "# x_train = (x_train - avg) / std\n",
    "\n",
    "df_train.shape, x_train.shape, df_test.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f396774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((85044, 52), (25955, 52))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate dataset\n",
    "\n",
    "# col_topo = ['elevation', 'slope']  # , 'aspect'\n",
    "torch.set_default_dtype(torch.float32)\n",
    "# cols = col_s2_band + col_topo\n",
    "\n",
    "train_x, test_x = df_train.loc[:, cols].values.astype(np.float32), df_test.loc[:, cols].values.astype(np.float32)\n",
    "idx_mask = ~(np.isinf(train_x) | np.isnan(train_x)).any(axis=1)\n",
    "idx_mask_test = ~(np.isinf(test_x) | np.isnan(test_x)).any(axis=1)\n",
    "\n",
    "train_x, test_x = train_x[idx_mask, ], test_x[idx_mask_test]\n",
    "\n",
    "# # multi classification\n",
    "# col_type = 'class_dec'  \n",
    "# train_y, test_y = df_train.loc[idx_mask, col_type]-1, df_test.loc[idx_mask_test, col_type]-1\n",
    "# trainDataset = TensorDataset(torch.tensor(train_x, dtype=torch.float32), torch.tensor(train_y, dtype=torch.long))\n",
    "# valDataset = TensorDataset(torch.tensor(test_x, dtype=torch.float32), torch.tensor(test_y ,dtype=torch.long))  # torch.int\n",
    "\n",
    "# binary classification\n",
    "col_type = 'class_2typ'  # origin 1 is cf, 2 is non-coffee, turn cf into 1, non-coffee into 0\n",
    "train_y, test_y = 2-df_train.loc[idx_mask, col_type], 2-df_test.loc[idx_mask_test, col_type]\n",
    "trainDataset = TensorDataset(torch.tensor(train_x, dtype=torch.float32), torch.tensor(train_y.values, dtype=torch.float32))\n",
    "valDataset = TensorDataset(torch.tensor(test_x, dtype=torch.float32), torch.tensor(test_y.values, dtype=torch.float32))  # torch.int\n",
    "\n",
    "batch_size = 256\n",
    "trainLoader = DataLoader(trainDataset, batch_size=batch_size, shuffle=True)\n",
    "valLoader = DataLoader(valDataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b5fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edb8b44c",
   "metadata": {},
   "source": [
    "## model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a6b7a0c-1ea3-483d-9154-68a167133ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model parameters\n",
    "pars_feas = [\n",
    "    [[10,5,50,20], [10,12,12,4]]\n",
    "]\n",
    "# [10,5,50,20] -> [10 bands from Sentinel-2, 5 time periods, 50 inputs features, 20 outputs]\n",
    "# [10,12,12,4] -> full connected network structure for Sentinel bands of each time period \n",
    "\n",
    "par_merge = [[20,2], [22,16,16,8,7]]\n",
    "# [22,0] -> 22 inputs from the outputs of formal feature preprocessing network\n",
    "# [22,16,16,8,7] -> network structure of feature combination\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    # define model parameters\n",
    "    def __init__(self, pars_feas=None, par_merge=None):  \n",
    "        super(DNN, self).__init__()\n",
    "\n",
    "        self.pars_feas = pars_feas\n",
    "        self.par_merge = par_merge\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # mdl list of all features are combined into one, and each feature is connected by a full connected layer to form an mdl list\n",
    "        list_mdl = []\n",
    "        # pars_fea [10,5,50,20], par_mdl [10,16,8,4]\n",
    "        for pars_fea,par_mdl in pars_feas:\n",
    "            list_mdl_fea = []  # used to store lyr of multiple layer\n",
    "            for t_idx in range(pars_fea[1]):\n",
    "                list_lyr = []\n",
    "                for i in range(len(par_mdl)-1):\n",
    "                    list_lyr.extend([nn.Linear(par_mdl[i],par_mdl[i+1]), self.relu])\n",
    "                list_mdl_fea.append(nn.Sequential(*list_lyr))\n",
    "            list_mdl.append(nn.ModuleList(list_mdl_fea))\n",
    "        self.fcs_fea = nn.ModuleList(list_mdl)\n",
    "\n",
    "        par_lyrs = par_merge[1]\n",
    "        list_lyr = []\n",
    "        for i in range(len(par_lyrs)-2):\n",
    "            list_lyr.extend([nn.Linear(par_lyrs[i],par_lyrs[i+1]), self.relu])\n",
    "        list_lyr.append(nn.Linear(par_lyrs[-2],par_lyrs[-1]))\n",
    "        self.fcs_end = nn.Sequential(*list_lyr)\n",
    "\n",
    "\n",
    "    # forward propagation process\n",
    "    def forward(self, x):\n",
    "        offset = 0\n",
    "        xs = []\n",
    "\n",
    "        # cycle a few times for certain types of features e.g. S2 and topology\n",
    "        for i in range(len(self.pars_feas)):\n",
    "            fea_pars = self.pars_feas[i][0]\n",
    "            # cycle each time period\n",
    "            for t_idx in range(fea_pars[1]):\n",
    "                \n",
    "                x_t = x[:, offset+t_idx*fea_pars[0]: offset+(t_idx+1)*fea_pars[0]]\n",
    "                # print(t_idx, 'x_t', x_t.shape)\n",
    "                xs.append(self.fcs_fea[i][t_idx](x_t))\n",
    "            offset += fea_pars[2]\n",
    "\n",
    "        # for x in xs:\n",
    "        #     print(x.shape)\n",
    "        if self.par_merge[0][1]:\n",
    "            x = torch.cat(xs+[x[:,offset:]], dim=1)\n",
    "        else:\n",
    "            x = torch.cat(xs, dim=1)  \n",
    "        # print(x.shape, self.fcs_end)\n",
    "        x = self.fcs_end(x)\n",
    "\n",
    "        # if it is binary classification, use sigmoid function to convert to binary result\n",
    "        if self.par_merge[-1][-1] == 1:\n",
    "            x = nn.Sigmoid()(x)\n",
    "            x = x.squeeze(-1)\n",
    "            \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b424102-6b2b-448f-9f09-dc200fe31f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if par_merge[-1][-1] == 1:\n",
    "    criterion = nn.BCELoss()  # binary classification\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()  # multi classification\n",
    "\n",
    "\n",
    "mdl = DNN(pars_feas=pars_feas, par_merge=par_merge).to(device)\n",
    "optimizer = optim.Adam(mdl.parameters(), lr=0.001)  # , weight_decay=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ade7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7298a1ca",
   "metadata": {},
   "source": [
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bece36-1aa1-4a3b-a4ba-4182c6fdb138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037c9b74-0e0c-49ca-8ea5-0cca05d26e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(assess).to_excel(f'result/mdl/DL_2022_{study_area_fn}_2yr.xlsx')  # data_path / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20290c02-c382-4370-809b-44a46cc9b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "assess = []\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    mdl.train()\n",
    "\n",
    "    train_loss_list, train_metric_list = [],[]\n",
    "\n",
    "    for inputs, labels in trainLoader:\n",
    "        # print('ipt_size', inputs.size())\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = mdl(inputs)\n",
    "        if par_merge[-1][-1] == 1:\n",
    "            labels = labels.squeeze(-1)\n",
    "        loss_i = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_i.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_list.append(loss_i.detach().cpu().numpy())\n",
    "\n",
    "    loss = np.mean(train_loss_list)\n",
    "\n",
    "    # Verify accuracy\n",
    "    mdl.eval()\n",
    "\n",
    "    outputs_list = []\n",
    "    labels_list = []\n",
    "    with torch.no_grad():\n",
    "        for ipts, lbls in valLoader:\n",
    "            inputs, labels = ipts.to(device), lbls.numpy()\n",
    "            outputs = mdl(inputs)\n",
    "\n",
    "            if par_merge[-1][-1] == 1:\n",
    "                outputs_list.append(outputs.detach().cpu().numpy())\n",
    "            else:\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                predicted = predicted.detach().cpu().numpy()\n",
    "                outputs_list.append(predicted)\n",
    "            \n",
    "            labels_list.append(labels)\n",
    "\n",
    "    if par_merge[-1][-1] == 1:\n",
    "        y_pred = np.concatenate(outputs_list) > 0.5\n",
    "    else:\n",
    "        y_pred = np.concatenate(outputs_list)\n",
    "    y_test = np.concatenate(labels_list)\n",
    "\n",
    "    s_report = sk.metrics.classification_report(y_test, y_pred)\n",
    "    report_res = s_report.split()\n",
    "    kp = sk.metrics.cohen_kappa_score(y_test, y_pred)\n",
    "    assess.append([epoch, loss]+report_res[5:8]+[report_res[report_res.index('accuracy')+1], kp])\n",
    "\n",
    "    if epoch%20 == 0:\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Train loss: {loss.item():.4f}, acc:{assess[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3a93a07-e976-4d40-a110-cf8b16defec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mdl_save = 'mdl_pars.pth'\n",
    "\n",
    "# torch.save(mdl, path_mdl_save)\n",
    "mdl = torch.load(path_mdl_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8010a919-016e-432c-8c11-caa54ba91d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb96230-1c57-4bb7-b044-252fa7c3c693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
